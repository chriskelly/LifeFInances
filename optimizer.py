"""Optimization Algorithm for Retirement Planning Simulator

This script allows the user to try to improve the success rate of a retirement plan
by trying different combinations of parameters.

Required installations are detailed in requirements.txt.

This file can also be imported as a module and contains the following function:

    * Algorithm.main() - An infinite loop that uses a genetic algoritm to search
                            for better parameter combinations

"""

import json
import time
import os
import numpy as np
import scipy.stats as ss
from simulator import Simulator
import simulator
import models.model
from models.model import Model
from models.user import User
import data.constants as const

if not os.path.exists(const.PARAMS_SUCCESS_LOC):
    with open(const.PARAMS_SUCCESS_LOC, 'w', encoding="utf-8"):
        pass

DEBUG_LVL = 2 # Lvl 0 shows only local and final max param sets
RESET_SUCCESS_TRACKER = False # Set to true to reset all the counts in param_success.json
INITIAL_SUCCESS_THRESH = 0.5 # Initial threshold before switching from random to step mutations
OFFSPRING_QTY = 10
TARGET_SUCCESS_RATE = 0.95
INITIAL_MONTE_RUNS = 100
MAX_MONTE_RUNS = 5000
ITER_LIMIT = 5 # Max number of times to run if parent is better than all children
SEED = True # Use current params to start with
RNG = np.random.default_rng()

class Algorithm:
    """
    This class is a genetic algorithm designed to find higher performing combinations of
    parameters.
    
    Attributes
    ----------
    reset_success_tracker : bool
        Whether to reset all the counts in `data/param_success.json`. These track the succcesses
        of a given option for each parameter.
    model : model
        Model for managing parameters and database connection
    mutable_param_ranges : dict
        {parameter:list of options} for parameters marked as optimizable 
        in `data/param_details.json`
    
    Methods
    -------
    main()
        Cycles through mutating parameter sets, testing those sets, finding the best, and
        continuing to mutate.
    
    """
    def __init__(self, model:Model):
        self.reset_success_tracker = RESET_SUCCESS_TRACKER
        self.model = model
        self.user = self.model.user
        self.mutable_parameters = self.user.optimizable_parameters()
        self.mutable_param_ranges = {param:User.__dict__[param].expression.__dict__['options']
                                     for param in self.mutable_parameters}
        self.prev_used_params = [] # track and prevent reusing same param sets during step mutation
        self.returns = [] # returns generated by the simulator can be stored and reused
        simulator.DEBUG_LVL = 0

    def main(self, recursing:bool = False):
        """Cycles through mutating parameter sets, testing those sets, finding the best, and
        continuing to mutate.
        
        User parameters are directly modified when a successful (success rate greater 
        than TARGET_SUCCESS_RATE) combination is found. Then the loop is restarted, but 
        any income profiles marked as 'try to optimize' are decremented by 0.25 years.

        Args:
            next_loop (boolean, dict), _optional_: Defaults to (False,[]). Boolean indicates
            if we're not in the first execution of the main(). The dict is the full_param_vals
            passed from the previous execution of the main().

        Raises:
            Exception: _description_

        Returns:
            None: Only returns if cancelled with external trigger.
        """
    # ---------------------- First parameter set ---------------------- #
        mutable_vals = {param:getattr(self.user, param) for param in self.mutable_parameters}
        success_rate, parent_is_best_qty = 0.0 , 0
        if recursing or SEED:
            parent_mutable_vals = mutable_vals
        else: # if not, keep random mutating till we hit SUCCESS_THRESH
            while success_rate <  INITIAL_SUCCESS_THRESH:
                success_rate, parent_mutable_vals = self._make_child(success_rate, 'random')
                if success_rate is None:
                    return # if cancelled
                if DEBUG_LVL >= 1:
                    print(f"Success Rate: {success_rate*100:.2f}%")
        self._update_param_count(parent_mutable_vals)
    # ---------------------- Improvement loop ---------------------- #
        while True:
            # Confirm if other cores have succeeded yet or not
            self._check_if_beaten()
            # Make children
            children = []
            for idx in range(OFFSPRING_QTY):
                self.model.log_to_optimize_page(f"Generating trial {idx+1}/{OFFSPRING_QTY}")
                children.append(self._make_child(success_rate, 'step',
                                                parent_mutable_vals,
                                                max_step=max(1, parent_is_best_qty),
                                                reuse_returns=idx))
                if not children[-1][0]:
                    return # if cancelled
            # Find best child (or use parent if all children worse)
                # Lambda func needed to avoid sorting by params if success rates are equal
            children.sort(key=lambda child: child[0], reverse=True)
            # ------ Children not improving ------ #
            if success_rate >= children[0][0]: # Parent better than child
                self.model.log_to_optimize_page('No improvement')
                parent_is_best_qty += 1
                if DEBUG_LVL>=1:
                    print(f"No better children {parent_is_best_qty}/{ITER_LIMIT}")
                # if children not improving, start over with random child
                if parent_is_best_qty >= ITER_LIMIT:
                    self.model.log_to_optimize_page(
                        f"Best found: {success_rate*100:.2f}%\n {parent_mutable_vals}")
                    print(f"Local max: {success_rate*100:.2f}%\n {parent_mutable_vals}")
                    parent_is_best_qty = 0
                    success_rate = 0.0
                    while success_rate <  INITIAL_SUCCESS_THRESH:
                        success_rate, parent_mutable_vals = self._make_child(success_rate, 'random')
                        if success_rate is None:
                            return # if cancelled
            # ------ Child is better ------ #
            else: # If child better than parent, update success rate and params
                parent_is_best_qty = 0
                success_rate, parent_mutable_vals = children[0]
                self._update_param_count(parent_mutable_vals)
                self.model.log_to_optimize_page('Found a better combination!')
                if DEBUG_LVL >= 1:
                    print(f"Success Rate: {success_rate*100:.2f}%")
            # ------ Child beats target, proceed to test child ------ #
            # Add a slight buffer to prevent osccilating between
            # barely beating it and failing upon retest
            if success_rate >= TARGET_SUCCESS_RATE * 1.005:
                self.model.log_to_optimize_page('Confirming combination works well...')
                current_monte_carlo_runs = simulator.MONTE_CARLO_RUNS # save previous value
                # test at higher monte carlo runs
                simulator.MONTE_CARLO_RUNS = MAX_MONTE_RUNS
                success_rate, _ = self._make_child(success_rate, 'identical', parent_mutable_vals)
                if not success_rate:
                    return # if cancelled
                simulator.MONTE_CARLO_RUNS = current_monte_carlo_runs
                if success_rate < TARGET_SUCCESS_RATE:
                    self.model.log_to_optimize_page("Wasn't actually better")
                    if DEBUG_LVL>=1:
                        print(f"Couldn't stand the pressure...{success_rate*100:.2f}%")
                else:
                    # Print results, overwrite params, start again with decremented income end dates
                    self._check_if_beaten()
                    self.model.log_to_optimize_page(
                        f"Found a good combination! {success_rate*100:.2f}%\n {parent_mutable_vals}"
                        )
                    print(f"Final max: {success_rate*100:.2f}%\n {parent_mutable_vals}")
                    self.model.update_from_optimizer(self.user)
                        # Reduce last dates by one quarter if desired
                    recursing = False # don't know yet if there's an income to reduce
                    usr_start_date = partner_start_date = models.model.TODAY_YR_QT
                    for profile in self.user.income_profiles:
                            # check if job will start before previous job ends
                        last_date = profile.last_date
                        if profile.is_partner_income:
                            duration = last_date - partner_start_date + 0.25
                            partner_start_date = last_date + 0.25 # adjust to next start_date
                        else:
                            duration = last_date - usr_start_date + 0.25
                            usr_start_date = last_date + 0.25
                        if not profile.try_to_optimize:
                            continue
                        usr = 'Partner' if profile.is_partner_income else 'User'
                        if duration <= 0.25:
                            print(f"{usr}'s income with Last Date of {last_date} ends too early")
                            continue
                            # Not sure how to better handle this. You could delete the income item
                            # in the params, but I don't think users would prefer the income be
                            # deleted. You could add some sort of skip tag to the income that
                            # income.py then uses to ignore, but that may not be easily debuggable
                        # now we've confirmed that there's a valid last date to reduce
                        recursing = True
                        profile.last_date -= 0.25
                        print(f"Now trying to reduce {usr}'s last date to {profile.last_date}!")
                        self.model.log_to_optimize_page(f"Now trying to reduce {usr}'s\
                            last date to {profile.last_date}!")
                    if recursing:
                            # Assuming dates for bond tent also needs to be reduced
                            # with earlier retire date
                        self.user.bond_tent_start_date -= 0.25
                        self.user.bond_tent_peak_date -= 0.25
                        self.user.bond_tent_end_date -= 0.25
                        self.main(recursing=True)

    # ---------------------- Mutation ---------------------- #
    def _random_mutate(self) -> dict:
        """Return mutable params_vals with shuffled values"""
         # random.choice doesn't always work on np.arrays,
         # so np.random.choice is used https://github.com/python/cpython/issues/100805
        return {param:np.random.choice(param_range) for (param,param_range)
                in self.mutable_param_ranges.items()}

    def _step_mutate(self, mutable_param_values:dict, max_step=1) -> dict:
        """Return mutable param_vals with values shifted in a normal distribution around
        provided mutable_param_values with a max deviation of max_step"""
        new_param_vals = {}
        for param, param_range in self.mutable_param_ranges.items():
            old_idx = param_range.index(mutable_param_values[param])
            new_idx = min(len(param_range)-1, max(0, self._gaussian_int(center=old_idx,
                                                                        max_deviation=max_step)))
            new_param_vals[param] = param_range[new_idx]
        if new_param_vals in self.prev_used_params:
            if DEBUG_LVL>=1:
                print(f'Tried params: {len(self.prev_used_params)}')
            new_param_vals = self._step_mutate(mutable_param_values,max_step)
        return new_param_vals

    # -------------------------------- HELPER FUNCTIONS -------------------------------- #
    def _check_if_beaten(self):
        """Checks to see if another process was able to find a successful parameter combination. 
        If so, start over.
        """
        currently_saved_user = Model().user
        for i, saved_profile in enumerate(currently_saved_user.income_profiles):
            if self.user.income_profiles[i].last_date > saved_profile.last_date:
                print('got beat')
                Algorithm(Model()).main() # start over if another instance found working parameters

    def _gaussian_int(self, center:int, max_deviation:int) -> int:
        """Returns an int from a random gaussian distribution
        https://stackoverflow.com/questions/37411633/how-to-generate-a-random-normal-distribution-of-integers

        Args:
            center (int): center of desired distribution
            max_deviation (int): 
                distribution will range from center-max_deviation to center+max_deviation

        Returns:
            int: random int from inclusive range with gaussian distribution
        """
        scale = max_deviation/1.5 # decreasing the demonimator results in a flater distribution
        value_range = np.arange(-max_deviation, max_deviation+1) + center
        up_shifted, down_shifted = value_range + 0.5, value_range - 0.5
        prob = ss.norm.cdf(up_shifted, loc = center, scale = scale)\
                - ss.norm.cdf(down_shifted, loc = center, scale = scale)
        prob = prob / prob.sum() # normalize the probabilities so their sum is 1
        return np.random.choice(value_range, p = prob)

    def _update_param_count(self,param_vals:dict):
        """Edit the `data/param_success.json` file to add another tally for each of the
        successful mutable parameter values. If first time and RESET_SUCCESS,
        overwrite previous file and set count to 0

        Args:
            param_vals (dict): 
                parameter:val pairs.
                The tracker will increment these mutable parameter option counts by 1
        """
        with open(const.PARAMS_SUCCESS_LOC, 'r+', encoding="utf-8") as json_file:
            try:
                param_cnt = json.load(json_file)
            except json.JSONDecodeError:
                param_cnt = {}
                self.reset_success_tracker = True
        if self.reset_success_tracker:
            self.reset_success_tracker = False
            param_cnt = {param:[0]*len(param_range) for param,param_range
                         in self.mutable_param_ranges.items()}
        for param, param_range in self.mutable_param_ranges.items():
            param_cnt[param][param_range.index(param_vals[param])] += 1
        with open(const.PARAMS_SUCCESS_LOC, 'w', encoding="utf-8") as outfile:
            json.dump(param_cnt, outfile, indent=4)

    def _make_child(self, success_rate:float, mutate:str, parent_mutable_vals:dict = None,
                    max_step:int = 1, reuse_returns:bool = False) -> tuple[float,dict]:
        """Mutate the given parameters and run a simulation.\n
        Mutate can be 'step', 'random', or 'identical'
        
        Args:
            success_rate (float): 
                The previous success rate. More simulations will be run as success rate increases.
            mutate (str): 
                'step': mutable parameters can shift up to the max_step (int)
                'random': mutable parameters will be shuffled
                'identical': no mutation will be made
            parent_mutable_param_vals (dict): the previously used mutable parameters
            max_step (int): the max shift of the mutable paramters if mutate = 'step'
            reuse_returns (bool): Reuse previously generated returns

        Raises:
            Exception: _description_

        Returns:
            _type_: _description_
        """
        if DEBUG_LVL >= 2:
            child_start_time = time.time()
        if mutate == 'step':
            child_mutable_vals = self._step_mutate(parent_mutable_vals, max_step)
            self.prev_used_params.append(child_mutable_vals)
        elif mutate == 'random':
            self.prev_used_params = []
            child_mutable_vals = self._random_mutate()
            self.prev_used_params.append(child_mutable_vals)
        elif mutate == 'identical':
            child_mutable_vals = parent_mutable_vals
        else:
            raise ValueError('no valid mutation chosen')
        for key, value in child_mutable_vals.items():
            setattr(self.user, key, value)
        # monte carlo runs are exponentially related to success rate.
        # Increasing the exponent makes the curve more severe.
        # At the TARGET_SUCCESS_RATE, you'll get the MAX_MONTE_RUNS
        override_dict = {'monte_carlo_runs' : int(max(INITIAL_MONTE_RUNS, (min(MAX_MONTE_RUNS,
                            (MAX_MONTE_RUNS * (success_rate + (1-TARGET_SUCCESS_RATE)) ** 70)))))}
        # If we're on the first child of a set, the simulator will generate returns
        # and feed them back. For the next children, that same set of returns will be reused.
        if reuse_returns:
            override_dict['returns']  = self.returns
        print(f"monte runs: {override_dict['monte_carlo_runs']}")
        new_simulator = Simulator(self.user, override_dict)
        sim_results = new_simulator.main()
        if not sim_results: # Simulator returns empty dict when quit commmand given
            return (None, None)
        self.returns = sim_results['returns']
        if DEBUG_LVL >= 2:
            child_end_time = time.time()
            print(f"child generation time: {round(child_end_time-child_start_time, 2)}")
        return sim_results['s_rate'], child_mutable_vals


if __name__ == '__main__':
    algorithm = Algorithm(Model())
    algorithm.main()
