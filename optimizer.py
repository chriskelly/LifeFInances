"""Optimization Algorithm for Retirement Planning Simulator

This script allows the user to try to improve the success rate of a retirement plan
by trying different combinations of parameters.

Required installations are detailed in requirements.txt.

This file can also be imported as a module and contains the following function:

    * Algorithm.main() - An infinite loop that uses a genetic algoritm to search
                            for better parameter combinations

"""

import json
import time
import os
import numpy as np # pylint: disable=unused-import # used in eval() of parameter ranges
import scipy.stats as ss
from simulator import Simulator
import simulator
import models.model
from models.model import Model
import data.constants as const

if not os.path.exists(const.PARAMS_SUCCESS_LOC):
    with open(const.PARAMS_SUCCESS_LOC, 'w', encoding="utf-8"):
        pass

DEBUG_LVL = 2 # Lvl 0 shows only local and final max param sets
RESET_SUCCESS_TRACKER = False # Set to true to reset all the counts in param_success.json
INITIAL_SUCCESS_THRESH = 0.5 # Initial threshold before switching from random to step mutations
OFFSPRING_QTY = 10
TARGET_SUCCESS_RATE = 0.95
INITIAL_MONTE_RUNS = 100
MAX_MONTE_RUNS = 5000
ITER_LIMIT = 5 # Max number of times to run if parent is better than all children
SEED = True # Use current params to start with
RNG = np.random.default_rng()

class Algorithm:
    """
    This class is a genetic algorithm designed to find higher performing combinations of
    parameters.
    
    Attributes
    ----------
    reset_success_tracker : bool
        Whether to reset all the counts in `data/param_success.json`. These track the succcesses
        of a given option for each parameter.
    model : model
        Model for managing parameters and database connection
    mutable_param_ranges : dict
        {parameter:list of options} for parameters marked as optimizable 
        in `data/param_details.json`
    
    Methods
    -------
    main()
        Cycles through mutating parameter sets, testing those sets, finding the best, and
        continuing to mutate.
    
    """
    def __init__(self, model:Model):
        self.reset_success_tracker = RESET_SUCCESS_TRACKER
        self.model = model
        self.mutable_param_ranges = {param:list(eval(str(obj['range']))) # pylint: disable=eval-used
                                     for param,obj in self.model.param_details.items()
                                     if 'optimizable' in obj} # input strings are controlled
        self.prev_used_params = [] # track and prevent reusing same param sets during step mutation
        self.returns = [] # returns generated by the simulator can be stored and reused
        simulator.DEBUG_LVL = 0

    def main(self, next_loop:tuple[bool,dict] = (False, {})):
        """Cycles through mutating parameter sets, testing those sets, finding the best, and
        continuing to mutate.
        
        User parameters are directly modified when a successful (success rate greater 
        than TARGET_SUCCESS_RATE) combination is found. Then the loop is restarted, but 
        any income profiles marked as 'try to optimize' are decremented by 0.25 years.

        Args:
            next_loop (boolean, dict), _optional_: Defaults to (False,[]). Boolean indicates
            if we're not in the first execution of the main(). The dict is the full_param_vals
            passed from the previous execution of the main().

        Raises:
            Exception: _description_

        Returns:
            None: Only returns if cancelled with external trigger.
        """
    # ---------------------- First parameter set ---------------------- #
        mute_param_vals = {param:val for param, val in self.model.user.__dict__.items()
                           if param in self.model.param_details
                           and 'optimizable' in self.model.param_details[param]}
        full_param_vals = {param:val for param, val in self.model.user.__dict__.items()
                           if param in self.model.param_details} # Needs to be a copy of the items
        success_rate, parent_is_best_qty = 0.0 , 0
        if next_loop[0]: # checks if we are we in a susequent loop
            full_param_vals = next_loop[1]
            parent_mute_param_vals = mute_param_vals
        elif SEED:
            parent_mute_param_vals = mute_param_vals
        else: # if not, keep random mutating till we hit SUCCESS_THRESH
            while success_rate <  INITIAL_SUCCESS_THRESH:
                success_rate, parent_mute_param_vals = self._make_child(full_param_vals,
                                                                        success_rate, 'random')
                if isinstance(success_rate, float):
                    return # if cancelled
                if DEBUG_LVL >= 1:
                    print(f"Success Rate: {success_rate*100:.2f}%")
        self._update_param_count(parent_mute_param_vals)
    # ---------------------- Improvement loop ---------------------- #
        while True:
            # Confirm if other cores have succeeded yet or not
            self._check_if_beaten(full_param_vals)
            # Make children
            children = []
            for idx in range(OFFSPRING_QTY):
                self.model.log_to_optimize_page(f"Generating trial {idx+1}/{OFFSPRING_QTY}")
                children.append(self._make_child(full_param_vals, success_rate, 'step',
                                                parent_mute_param_vals,
                                                max_step=max(1, parent_is_best_qty),
                                                reuse_returns=idx))
                if not children[-1][0]:
                    return # if cancelled
            # Find best child (or use parent if all children worse)
                # Lambda func needed to avoid sorting by params if success rates are equal
            children.sort(key=lambda child: child[0], reverse=True)
            # ------ Children not improving ------ #
            if success_rate >= children[0][0]: # Parent better than child
                self.model.log_to_optimize_page('No improvement')
                parent_is_best_qty += 1
                if DEBUG_LVL>=1:
                    print(f"No better children {parent_is_best_qty}/{ITER_LIMIT}")
                # if children not improving, start over with random child
                if parent_is_best_qty >= ITER_LIMIT:
                    self.model.log_to_optimize_page(
                        f"Best found: {success_rate*100:.2f}%\n {parent_mute_param_vals}")
                    print(f"Local max: {success_rate*100:.2f}%\n {parent_mute_param_vals}")
                    parent_is_best_qty = 0
                    success_rate = 0.0
                    while success_rate <  INITIAL_SUCCESS_THRESH:
                        success_rate, parent_mute_param_vals = self._make_child(full_param_vals,
                                                                            success_rate, 'random')
                        if not success_rate:
                            return # if cancelled
            # ------ Child is better ------ #
            else: # If child better than parent, update success rate and params
                parent_is_best_qty = 0
                success_rate, parent_mute_param_vals = children[0]
                self._update_param_count(parent_mute_param_vals)
                self.model.log_to_optimize_page('Found a better combination!')
                if DEBUG_LVL >= 1:
                    print(f"Success Rate: {success_rate*100:.2f}%")
            # ------ Child beats target, proceed to test child ------ #
            # Add a slight buffer to prevent osccilating between
            # barely beating it and failing upon retest
            if success_rate >= TARGET_SUCCESS_RATE * 1.005:
                self.model.log_to_optimize_page('Confirming combination works well...')
                current_monte_carlo_runs = simulator.MONTE_CARLO_RUNS # save previous value
                # test at higher monte carlo runs
                simulator.MONTE_CARLO_RUNS = MAX_MONTE_RUNS
                success_rate, _ = self._make_child(full_param_vals, success_rate, 'identical',
                                                   parent_mute_param_vals)
                if not success_rate:
                    return # if cancelled
                simulator.MONTE_CARLO_RUNS = current_monte_carlo_runs
                if success_rate < TARGET_SUCCESS_RATE:
                    self.model.log_to_optimize_page("Wasn't actually better")
                    if DEBUG_LVL>=1:
                        print(f"Couldn't stand the pressure...{success_rate*100:.2f}%")
                else:
                    # Print results, overwrite params, start again with decremented income end dates
                    self._check_if_beaten(full_param_vals)
                    self.model.log_to_optimize_page(
                        f"Found a good combination! {success_rate*100:.2f}%\n {parent_mute_param_vals}") # pylint: disable=line-too-long # can't break apart f string
                    print(f"Final max: {success_rate*100:.2f}%\n {parent_mute_param_vals}")
                    full_param_vals.update(parent_mute_param_vals)
                    self.model.save_from_genetic(parent_mute_param_vals,
                                                 reduce_dates = next_loop[0])
                    full_param_vals = self.model.param_vals.copy()
                    self.main(next_loop=(True, full_param_vals))

    # ---------------------- Mutation ---------------------- #
    def _random_mutate(self) -> dict:
        """Return mutable params_vals with shuffled values"""
         # random.choice doesn't always work on np.arrays,
         # so np.random.choice is used https://github.com/python/cpython/issues/100805
        return {param:np.random.choice(param_range) for (param,param_range)
                in self.mutable_param_ranges.items()}

    def _step_mutate(self, mutable_param_values:dict, max_step=1) -> dict:
        """Return mutable param_vals with values shifted in a normal distribution around
        provided mutable_param_values with a max deviation of max_step"""
        new_param_vals = {}
        for param, param_range in self.mutable_param_ranges.items():
            old_idx = param_range.index(mutable_param_values[param])
            new_idx = min(len(param_range)-1, max(0, self._gaussian_int(center=old_idx,
                                                                        max_deviation=max_step)))
            new_param_vals[param] = param_range[new_idx]
        if new_param_vals in self.prev_used_params:
            if DEBUG_LVL>=1:
                print(f'Tried params: {len(self.prev_used_params)}')
            new_param_vals = self._step_mutate(mutable_param_values,max_step)
        return new_param_vals

    # -------------------------------- HELPER FUNCTIONS -------------------------------- #

    def _check_if_beaten(self, full_param_vals:dict):
        """Checks to see if another process was able to find a successful parameter combination.

        If so, start over.

        Args:
            full_param_vals (dict): _description_
        """
        current_param_vals = models.model.load_params()[0]
        for usr in ['user','partner']:
            for i, income in enumerate(full_param_vals[f'{usr}_jobs']):
                if income["last_date"] > current_param_vals[f'{usr}_jobs'][i]["last_date"]:
                    print('got beat')
                    self.main() # start over if another instance found working parameters

    def _gaussian_int(self, center:int, max_deviation:int) -> int:
        """Returns an int from a random gaussian distribution
        https://stackoverflow.com/questions/37411633/how-to-generate-a-random-normal-distribution-of-integers

        Args:
            center (int): center of desired distribution
            max_deviation (int): 
                distribution will range from center-max_deviation to center+max_deviation

        Returns:
            int: random int from inclusive range with gaussian distribution
        """
        scale = max_deviation/1.5 # decreasing the demonimator results in a flater distribution
        value_range = np.arange(-max_deviation, max_deviation+1) + center
        up_shifted, down_shifted = value_range + 0.5, value_range - 0.5
        prob = ss.norm.cdf(up_shifted, loc = center, scale = scale)\
                - ss.norm.cdf(down_shifted, loc = center, scale = scale)
        prob = prob / prob.sum() # normalize the probabilities so their sum is 1
        return np.random.choice(value_range, p = prob)

    def _update_param_count(self,param_vals:dict):
        """Edit the `data/param_success.json` file to add another tally for each of the
        successful mutable parameter values. If first time and RESET_SUCCESS,
        overwrite previous file and set count to 0

        Args:
            param_vals (dict): 
                parameter:val pairs.
                The tracker will increment these mutable parameter option counts by 1
        """
        with open(const.PARAMS_SUCCESS_LOC, 'r+', encoding="utf-8") as json_file:
            try:
                param_cnt = json.load(json_file)
            except json.JSONDecodeError:
                param_cnt = {}
                self.reset_success_tracker = True
        if self.reset_success_tracker:
            self.reset_success_tracker = False
            param_cnt = {param:[0]*len(param_range) for param,param_range
                         in self.mutable_param_ranges.items()}
        for param,param_range in self.mutable_param_ranges.items():
            param_cnt[param][param_range.index(param_vals[param])] += 1
        with open(const.PARAMS_SUCCESS_LOC, 'w', encoding="utf-8") as outfile:
            json.dump(param_cnt, outfile, indent=4)

    def _make_child(self, full_param_vals:dict, success_rate:float, mutate:str,
                    parent_mute_param_vals:dict = None, max_step:int = 1,
                    reuse_returns:bool = False) -> tuple[float,dict]:
        """Mutate the given parameters and run a simulation.\n
        Mutate can be 'step', 'random', or 'identical'
        
        Args:
            full_param_vals (dict): All the parameters to be passed to the simulation
            success_rate (float): 
                The previous success rate. More simulations will be run as success rate increases.
            mutate (str): 
                'step': mutable parameters can shift up to the max_step (int)
                'random': mutable parameters will be shuffled
                'identical': no mutation will be made
            parent_mute_param_vals (dict): the previously used mutable parameters
            max_step (int): the max shift of the mutable paramters if mutate = 'step'
            reuse_returns (bool): Reuse previously generated returns

        Raises:
            Exception: _description_

        Returns:
            _type_: _description_
        """
        if DEBUG_LVL >= 2:
            child_start_time = time.time()
        if mutate == 'step':
            child_mute_param_vals = self._step_mutate(parent_mute_param_vals,max_step=max_step)
            self.prev_used_params.append(child_mute_param_vals)
        elif mutate == 'random':
            self.prev_used_params = []
            child_mute_param_vals = self._random_mutate()
            self.prev_used_params.append(child_mute_param_vals)
        elif mutate == 'identical':
            child_mute_param_vals = parent_mute_param_vals
        else:
            raise ValueError('no valid mutation chosen')
        full_param_vals.update(child_mute_param_vals)
        # monte carlo runs are exponentially related to success rate.
        # Increasing the exponent makes the curve more severe.
        # At the TARGET_SUCCESS_RATE, you'll get the MAX_MONTE_RUNS
        override_dict = {'monte_carlo_runs' : int(max(INITIAL_MONTE_RUNS, (min(MAX_MONTE_RUNS,
                            (MAX_MONTE_RUNS * (success_rate + (1-TARGET_SUCCESS_RATE)) ** 70)))))}
        # If we're on the first child of a set, the simulator will generate returns
        # and feed them back. For the next children, that same set of returns will be reused.
        if reuse_returns:
            override_dict['returns']  = self.returns
        print(f"monte runs: {override_dict['monte_carlo_runs']}")
        new_simulator = Simulator(full_param_vals, override_dict)
        sim_results = new_simulator.main()
        if not sim_results: # Simulator returns empty dict when quit commmand given
            return (None, None)
        self.returns = sim_results['returns']
        if DEBUG_LVL >= 2:
            child_end_time = time.time()
            print(f"child generation time: {round(child_end_time-child_start_time, 2)}")
        return sim_results['s_rate'], child_mute_param_vals


if __name__ == '__main__':
    algorithm = Algorithm(Model())
    algorithm.main()
