{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to generate synthetic data which has the same variability as the historical data. In particular, we want the synthetic data to have the same covariance matrix as the historical data.\n",
    "## Which variables should be included in this covariance matrix?\n",
    "Some of the variables do not look Normal, and therefore the multivariate_normal method will always fail to make data that resembles the original distributions. Based on the histograms, Treasury Rate, home price index, mortgage rate, rent index, and vacancy rate seem more like uniform distributions (though home price index looks potentially like a bimodal Normal). I would exclude these variables from this data generation process. In the last cell, I generated new data without these variables included in the covariance matrix. The plots didn't change much, but at least it's easier to focus on the variables where you have a chance at modelling them as Normal.\n",
    "### End goal -> Input needed\n",
    "The output of this data generation should be return rates that can be multiplied by a portfolio value to give a return. Due to the time-dependency of some of the indexes, indexes are not always as valuable a output as the derivative of the indexes. We need the values that are going to show the most accurate/useful co-variances.\n",
    "| Value | Index | Derivative | Which to use |\n",
    "| :- | -: | :-: | :-: |\n",
    "| Equity | S&P 500 Index | Return rate | Derivative\n",
    "| Inflation | CPI | Inflation rate | CPI\n",
    "| Bonds | Treasury 10-Year Yield | Rate of change | Index\n",
    "| RE Appreciation | Home Price Index | Appreciation | Derivative\n",
    "| RE Borrowing Cost | 30-Year Fixed Rate Mortgage | Rate of change | Index\n",
    "| RE Income | Rent Index | Rate of change | Derivative\n",
    "| RE Vacancy | Rental Vacancy Rate | Rate of change | Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_quart_rate = pd.read_csv('SP500_quart_rate.csv',header=0,names=['DATE','SP500_Return'])\n",
    "inflation_quart_rate = pd.read_csv('inflation_quart_rate.csv',header=0,names=['DATE','CPI','Inflation_Rate'])\n",
    "treasury_bond_quart_rate = pd.read_csv('treasury_bond_quart_rate.csv',header=0,names=['DATE','Treasury_Yield','Treasury_Yield_Change'])\n",
    "home_price_quart_rate = pd.read_csv('home_price_quart_rate.csv',header=0,names=['DATE','Home_Price_Index','Home_Price_Appreciation'])\n",
    "mortgage_quart_rate = pd.read_csv('mortgage_quart_rate.csv',header=0,names=['DATE','Mortgage_Rate','Mortgage_Rate_Change'])\n",
    "rent_quart_rate = pd.read_csv('rent_quart_rate.csv',header=0,names=['DATE','Rent_Index','Rent_Change'])\n",
    "vacancy_quart_rate = pd.read_csv('vacancy_quart_rate.csv',header=0,names=['DATE','Vacancy_Rate','Vacancy_Rate_Change'])\n",
    "\n",
    "merged_df = SP500_quart_rate.merge(inflation_quart_rate, how='left',left_on='DATE', right_on='DATE')\n",
    "merged_df = merged_df.merge(treasury_bond_quart_rate, how='left',left_on='DATE', right_on='DATE')\n",
    "merged_df = merged_df.merge(home_price_quart_rate, how='left',left_on='DATE', right_on='DATE')\n",
    "merged_df = merged_df.merge(mortgage_quart_rate, how='left',left_on='DATE', right_on='DATE')\n",
    "merged_df = merged_df.merge(rent_quart_rate, how='left',left_on='DATE', right_on='DATE')\n",
    "merged_df = merged_df.merge(vacancy_quart_rate, how='left',left_on='DATE', right_on='DATE')\n",
    "merged_df.drop(columns=['Treasury_Yield_Change','CPI','Home_Price_Index','Mortgage_Rate_Change','Rent_Index','Vacancy_Rate_Change'],inplace=True)\n",
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['DATE']= pd.to_datetime(merged_df['DATE'])\n",
    "sn.set_style('whitegrid')\n",
    "sn.relplot(data=merged_df, x='DATE', y='SP500_Return',\n",
    "           aspect=3\n",
    "          )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.relplot(data=merged_df, x='DATE', y='Inflation_Rate',\n",
    "           aspect=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.relplot(data=merged_df, x='SP500_Return',\n",
    "            y='Inflation_Rate', aspect=1.5\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.relplot(data=merged_df, x='Home_Price_Appreciation',\n",
    "            y='Inflation_Rate', aspect=1.5\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "covMatrix = merged_df.cov()\n",
    "print(covMatrix)\n",
    "# sn.heatmap(covMatrix, vmin=-1, vmax=1, center=0)\n",
    "sn.heatmap(covMatrix, center=0)\n",
    "plt.title('Change columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covMatrix = merged_df.drop(columns='DATE').cov().values\n",
    "mu = merged_df.drop(columns='DATE').mean().values\n",
    "print(\"Shape of covariance matrix\",covMatrix.shape)\n",
    "print(\"Shape of averages\", mu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 300\n",
    "rng = np.random.default_rng()\n",
    "gen_data = rng.multivariate_normal(mu, covMatrix, size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, col in enumerate(merged_df.drop(columns='DATE').columns):\n",
    "    plt.figure()\n",
    "    plt.title(col)\n",
    "    #use the same bins for both plots and normalize the density\n",
    "    _, bins, _= plt.hist(merged_df[col],label='original', density=True)\n",
    "    plt.hist(gen_data[idx],label='generated', bins=bins, density=True, alpha=0.7)\n",
    "    plt.ylabel('probability density')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2drop=['DATE', 'Treasury_Yield','Home_Price_Index',\n",
    "          'Mortgage_Rate','Rent_Index', 'Vacancy_Rate'\n",
    "         ]\n",
    "covMatrix = merged_df.drop(columns=col2drop).cov().values\n",
    "mu = merged_df.drop(columns=col2drop).mean().values\n",
    "gen_data = rng.multivariate_normal(mu, covMatrix, size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, col in enumerate(merged_df.drop(columns=col2drop).columns):\n",
    "    plt.figure()\n",
    "    plt.title(col)\n",
    "    #use the same bins for both plots and normalize the density\n",
    "    _, bins, _= plt.hist(merged_df[col],label='original', density=True)\n",
    "    plt.hist(gen_data[idx],label='generated', bins=bins, density=True, alpha=0.7)\n",
    "    plt.ylabel('probability density')\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
